{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Official Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import pymetis\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx, k_hop_subgraph, subgraph\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import networkx as nx\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import optuna\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utils.graph_processing import get_device\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device=get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_processing import load_config\n",
    "config=load_config(config_path=\"config.yaml\")\n",
    "\n",
    "# config\n",
    "DA_NA=config[\"dataset\"][\"name\"]\n",
    "DA_RO=config[\"dataset\"][\"root\"]\n",
    "OPLR=config[\"optimizer\"][\"lr\"]\n",
    "OPWE=float(config[\"optimizer\"][\"weight_decay\"])\n",
    "TE=config[\"train_model\"][\"epochs\"]\n",
    "PI=config[\"train_model\"][\"PrintI\"]\n",
    "HIDEEN_DIM=config[\"GNNModel\"][\"hidden_dim\"]\n",
    "OG=config[\"OG\"][\"node_num\"]\n",
    "PG=config[\"PG\"][\"node_num\"]\n",
    "PARTITION_KMIN=config[\"partition_k\"][\"k_min\"]\n",
    "PARTITION_KMAX=config[\"partition_k\"][\"k_max\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OriGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_processing import load_and_describe_dataset\n",
    "\n",
    "# load\n",
    "dataset,data=load_and_describe_dataset(dataset_name=DA_NA,root=DA_RO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gnn_models import GNNModel\n",
    "from utils.model_utils import train_model\n",
    "\n",
    "\n",
    "model = GNNModel(num_node_features=dataset.num_node_features,hidden_dim=HIDEEN_DIM,num_classes=dataset.num_classes).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=OPLR, weight_decay=OPWE)\n",
    "\n",
    "trained_model=train_model(model, data, optimizer, num_epochs=TE, print_interval=PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import evaluate_model\n",
    "\n",
    "test_accuracy = evaluate_model(trained_model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret On OriGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.explainer_utils import calculate_fidelity\n",
    "\n",
    "fid_positive_list = []\n",
    "fid_negative_list = []\n",
    "probs = []\n",
    "labels = []\n",
    "\n",
    "total_nodes = data.num_nodes if hasattr(data, 'num_nodes') else data.x.shape[0]\n",
    "\n",
    "\n",
    "num_nodes_to_process = min(OG, data.num_nodes)\n",
    "random_indices = random.sample(range(total_nodes), num_nodes_to_process)\n",
    "\n",
    "for node_idx in tqdm(random_indices):\n",
    "    \n",
    "    fid_pos, fid_neg, prob, label = calculate_fidelity(trained_model, data, node_idx)\n",
    "    if fid_pos is not None and fid_neg is not None:\n",
    "        fid_positive_list.append(fid_pos)\n",
    "        fid_negative_list.append(fid_neg)\n",
    "        probs.append(prob)\n",
    "        labels.append(label)\n",
    "    else:\n",
    "        print(f\"Node {node_idx}: Fidelity scores are None.\")\n",
    "\n",
    "mean_fid_positive = np.mean(fid_positive_list)\n",
    "mean_fid_negative = np.mean(fid_negative_list)\n",
    "print(f'Fid+：{mean_fid_positive:.4f}')\n",
    "print(f'Fid-：{mean_fid_negative:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_partition import partition_graph, extract_partition_subgraph\n",
    "from utils.model_utils import evaluate_proxy_model\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    nparts = trial.suggest_int('nparts', PARTITION_KMIN, PARTITION_KMAX)\n",
    "    num_trials = 5\n",
    "    total_val_loss, total_val_acc = 0, 0\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "        parts = partition_graph(data, nparts)\n",
    "        selected_partition = np.random.randint(0, nparts)\n",
    "        proxy_data = extract_partition_subgraph(data, parts, selected_partition)\n",
    "        val_loss, val_acc = evaluate_proxy_model(proxy_data)\n",
    "        total_val_loss += val_loss\n",
    "        total_val_acc += val_acc\n",
    "    avg_val_loss = total_val_loss / num_trials\n",
    "    avg_val_acc = total_val_acc / num_trials\n",
    "\n",
    "    if not hasattr(objective, 'best_loss') or avg_val_loss < objective.best_loss:\n",
    "        objective.best_loss, objective.best_acc = avg_val_loss, avg_val_acc\n",
    "        print(f\"New Best: nparts = {nparts}, avg_val_loss = {avg_val_loss:.4f}, avg_val_acc = {avg_val_acc:.4f}\")\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "best_nparts=study.best_params['nparts']\n",
    "\n",
    "\n",
    "print(f\"Best nparts = {study.best_params['nparts']}, Best Loss = {study.best_value:.4f}\")\n",
    "print(f\"Best Accuracy = {objective.best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_processing import combined_graph\n",
    "\n",
    "combined_subgraph = combined_graph(data, best_nparts, device=device)\n",
    "print(f\"\\nFinally Combine sum: {combined_subgraph.num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.model_utils import ProxyGNNModel\n",
    "from utils.model_utils import train_proxy_model_on_combined_subgraph\n",
    "from utils import model_utils\n",
    "import importlib\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "\n",
    "proxy_model, combined_subgraph = train_proxy_model_on_combined_subgraph(data, combined_subgraph, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret on subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_positive_list, fid_negative_list, probs_list, labels_list = [], [], [], []\n",
    "total_nodes = combined_subgraph.num_nodes\n",
    "num_nodes_to_process = min(PG, total_nodes)\n",
    "nodes_to_process = range(total_nodes) if total_nodes <= 50 else random.sample(range(total_nodes), num_nodes_to_process)\n",
    "\n",
    "for node_idx in tqdm(nodes_to_process):\n",
    "    \n",
    "    fid_pos, fid_neg, prob, label = calculate_fidelity(proxy_model, data, node_idx)\n",
    "    if fid_pos is not None and fid_neg is not None:\n",
    "        fid_positive_list.append(fid_pos)\n",
    "        fid_negative_list.append(fid_neg)\n",
    "        probs_list.append(prob)\n",
    "        labels_list.append(label)\n",
    "\n",
    "    mean_fid_positive = np.mean(fid_positive_list)\n",
    "    mean_fid_negative = np.mean(fid_negative_list)\n",
    "    print(f'Average Fid+: {mean_fid_positive:.4f}')\n",
    "    print(f'Average Fid-: {mean_fid_negative:.4f}')\n",
    "\n",
    "    classes = np.arange(dataset.num_classes)\n",
    "    labels_binarized = label_binarize(labels_list, classes=classes)\n",
    "    probs_array = np.array(probs_list)\n",
    "\n",
    "    if probs_array.shape[1] != dataset.num_classes:\n",
    "        if probs_array.shape[1] < dataset.num_classes:\n",
    "            probs_array = np.hstack((probs_array, np.zeros((probs_array.shape[0], dataset.num_classes - probs_array.shape[1]))))\n",
    "        else:\n",
    "            probs_array = probs_array[:, :dataset.num_classes]\n",
    "\n",
    "    unique_labels = np.unique(labels_list)\n",
    "    if len(unique_labels) < 2:\n",
    "        print(\"Warning: Only one class present in predictions. AUC-ROC cannot be calculated.\")\n",
    "    else:\n",
    "        auc_roc = (\n",
    "            roc_auc_score(labels_binarized, probs_array[:, 1]) if dataset.num_classes == 2\n",
    "            else roc_auc_score(labels_binarized, probs_array, average='macro', multi_class='ovr')\n",
    "        )\n",
    "        print(f'AUC-ROC: {auc_roc:.4f}' if auc_roc is not None else \"AUC-ROC cannot be calculated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsbe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
